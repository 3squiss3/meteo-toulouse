import logging
import logging.config
import click
import sys
from pathlib import Path

# Ajouter le r√©pertoire racine au PYTHONPATH
sys.path.append(str(Path(__file__).parent.absolute()))

from config import config, LoggingConfig, KafkaConfig

# Configuration des logs
logging.config.dictConfig(LoggingConfig.get_logging_config())
logger = logging.getLogger(__name__)

@click.group()
@click.version_option(version=config.APP_VERSION)
def cli():
    """
    üå§Ô∏è Plateforme d'Analyse M√©t√©orologique Toulouse
    
    Syst√®me de collecte, traitement et analyse des donn√©es m√©t√©o en temps r√©el
    """
    logger.info(f"D√©marrage de {config.APP_NAME} v{config.APP_VERSION}")

@cli.group()
def collect():
    """Commandes de collecte de donn√©es"""
    pass

@collect.command()
@click.option('--station', default='compans', 
              type=click.Choice(['compans', 'meteopole', 'all']),
              help='Station m√©t√©o √† collecter')
@click.option('--limit', default=10, help='Nombre max d\'enregistrements')
@click.option('--save', is_flag=True, help='Sauvegarder en CSV')
@click.option('--kafka', is_flag=True, help='Envoyer vers Kafka')
def meteo(station, limit, save, kafka):
    """Collecte les donn√©es m√©t√©o de Toulouse (nouveau syst√®me)"""
    logger.info(f"Collecte m√©t√©o - Station: {station}, Limit: {limit}")
    
    try:
        if station == 'all':
            # Collecte multi-stations
            from data_collection.collectors.toulouse_collector import CombinedMeteoCollector
            
            collector = CombinedMeteoCollector()
            data = collector.collect_all_stations(limit=limit, send_to_kafka=kafka)
            
            if not data.empty:
                click.echo(f"‚úÖ {len(data)} enregistrements de {data['station'].nunique()} stations")
                click.echo(data.head().to_string())
                
                if save:
                    filename = f"meteo_all_stations_{limit}.csv"
                    data.to_csv(config.DATA_DIR / "raw" / filename, index=False)
                    click.echo(f"üíæ Donn√©es sauvegard√©es dans {filename}")
            else:
                click.echo("‚ùå Aucune donn√©e collect√©e")
        
        else:
            # Collecte station simple
            from data_collection.collectors.toulouse_collector import ToulouseMeteoCollector
            
            collector = ToulouseMeteoCollector()
            
            if kafka:
                # Collecte et envoi direct vers Kafka
                success = collector.collect_and_send_to_kafka(limit=limit)
                if success:
                    click.echo(f"‚úÖ Donn√©es envoy√©es vers Kafka")
                else:
                    click.echo("‚ùå √âchec envoi Kafka")
            else:
                # Collecte normale
                data = collector.get_latest_data(limit=limit)
                
                if not data.empty:
                    click.echo(f"‚úÖ {len(data)} enregistrements collect√©s")
                    click.echo(data[['timestamp', 'station_name', 'temperature', 'humidite']].head().to_string())
                    
                    if save:
                        filename = f"meteo_{station}_{limit}.csv"
                        data.to_csv(config.DATA_DIR / "raw" / filename, index=False)
                        click.echo(f"üíæ Donn√©es sauvegard√©es dans {filename}")
                else:
                    click.echo("‚ùå Aucune donn√©e collect√©e")
            
            # Fermer les connexions
            collector.close()
            
    except ImportError as e:
        click.echo(f"‚ùå Erreur d'import: {e}")
        click.echo("V√©rifiez que les collecteurs sont correctement install√©s")
    except Exception as e:
        logger.error(f"Erreur lors de la collecte: {e}")
        click.echo(f"‚ùå Erreur: {e}")

@collect.command()
def all():
    """Collecte toutes les donn√©es (m√©t√©o + alertes + √©v√©nements)"""
    logger.info("Collecte compl√®te de toutes les donn√©es")
    
    try:
        from data_collection.collectors.toulouse_collector import ToulouseMeteoCollector, CombinedMeteoCollector
        
        # M√©t√©o multi-stations
        click.echo("üìä Collecte des donn√©es m√©t√©o multi-stations...")
        combined_collector = CombinedMeteoCollector()
        meteo_data = combined_collector.collect_all_stations(limit=20, send_to_kafka=True)
        
        # M√©t√©o principale (Compans)
        click.echo("üå§Ô∏è Collecte station principale (Compans)...")
        main_collector = ToulouseMeteoCollector()
        main_data = main_collector.get_latest_data(limit=10)
        
        # Envoyer vers Kafka
        if not main_data.empty:
            main_collector.send_to_kafka(main_data)
        
        # Fermer connexions
        main_collector.close()
        
        # R√©sum√©
        click.echo(f"\n‚úÖ Collecte termin√©e:")
        if not meteo_data.empty:
            click.echo(f"  ‚Ä¢ Donn√©es multi-stations: {len(meteo_data)} enregistrements")
            click.echo(f"  ‚Ä¢ Stations actives: {meteo_data['station'].nunique()}")
        if not main_data.empty:
            click.echo(f"  ‚Ä¢ Station principale: {len(main_data)} enregistrements")
        click.echo(f"  ‚Ä¢ Donn√©es envoy√©es vers Kafka: ‚úÖ")
        
    except Exception as e:
        logger.error(f"Erreur lors de la collecte compl√®te: {e}")
        click.echo(f"‚ùå Erreur: {e}")

@collect.command()
@click.option('--mode', default='batch', type=click.Choice(['batch', 'streaming']), 
              help='Mode de collecte')
@click.option('--interval', default=300, help='Intervalle en secondes pour le streaming')
def continuous(mode, interval):
    """Collecte continue pour alimenter Kafka en temps r√©el"""
    logger.info(f"Collecte continue en mode {mode}")
    
    try:
        from data_collection.collectors.toulouse_collector import CombinedMeteoCollector
        import time
        
        collector = CombinedMeteoCollector()
        
        if mode == 'streaming':
            click.echo(f"üîÑ Collecte streaming toutes les {interval} secondes...")
            click.echo("‚èπÔ∏è  Ctrl+C pour arr√™ter")
            
            try:
                while True:
                    click.echo(f"\nüì° Collecte √† {datetime.now().strftime('%H:%M:%S')}")
                    
                    # Collecter et envoyer vers Kafka
                    data = collector.collect_all_stations(limit=5, send_to_kafka=True)
                    
                    if not data.empty:
                        click.echo(f"‚úÖ {len(data)} enregistrements envoy√©s vers Kafka")
                    else:
                        click.echo("‚ö†Ô∏è  Aucune donn√©e collect√©e")
                    
                    time.sleep(interval)
                    
            except KeyboardInterrupt:
                click.echo("\n‚èπÔ∏è  Collecte streaming arr√™t√©e")
        
        else:
            # Mode batch
            click.echo("üì¶ Collecte batch...")
            data = collector.collect_all_stations(limit=50, send_to_kafka=True)
            
            if not data.empty:
                click.echo(f"‚úÖ {len(data)} enregistrements trait√©s")
                
                # Sauvegarder pour traitement Spark
                filename = f"meteo_batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                data.to_csv(config.DATA_DIR / "raw" / filename, index=False)
                click.echo(f"üíæ Sauvegard√©: {filename}")
            
    except Exception as e:
        logger.error(f"Erreur collecte continue: {e}")
        click.echo(f"‚ùå Erreur: {e}")

@cli.group()
def db():
    """Commandes de gestion de base de donn√©es"""
    pass

@db.command()
def init():
    """Initialise les bases de donn√©es"""
    logger.info("Initialisation des bases de donn√©es")
    
    try:
        from database.sql.init_postgresql import init_postgresql_schema
        from database.mongodb.init_mongodb import init_mongodb_collections
        
        click.echo("üêò Initialisation PostgreSQL...")
        init_postgresql_schema()
        
        click.echo("üçÉ Initialisation MongoDB...")
        init_mongodb_collections()
        
        click.echo("‚úÖ Bases de donn√©es initialis√©es")
        
    except ImportError:
        click.echo("‚ùå Modules de base de donn√©es non trouv√©s")
    except Exception as e:
        logger.error(f"Erreur initialisation DB: {e}")
        click.echo(f"‚ùå Erreur: {e}")

@db.command()
def status():
    """V√©rifie le statut des bases de donn√©es"""
    click.echo("üîç V√©rification du statut des bases de donn√©es...")
    
    # PostgreSQL
    try:
        import psycopg2
        from config import DatabaseConfig
        conn = psycopg2.connect(DatabaseConfig.POSTGRES_URL)
        conn.close()
        click.echo("üêò PostgreSQL: ‚úÖ Connect√©")
    except Exception as e:
        click.echo(f"üêò PostgreSQL: ‚ùå Erreur - {e}")
    
    # MongoDB
    try:
        from pymongo import MongoClient
        from config import DatabaseConfig
        client = MongoClient(DatabaseConfig.MONGODB_URL)
        client.admin.command('ping')
        click.echo("üçÉ MongoDB: ‚úÖ Connect√©")
        client.close()
    except Exception as e:
        click.echo(f"üçÉ MongoDB: ‚ùå Erreur - {e}")
    
    # SQLite
    try:
        import sqlite3
        from config import DatabaseConfig
        conn = sqlite3.connect(DatabaseConfig.SQLITE_PATH)
        conn.close()
        click.echo("üìÅ SQLite: ‚úÖ Accessible")
    except Exception as e:
        click.echo(f"üìÅ SQLite: ‚ùå Erreur - {e}")

@cli.group()
def process():
    """Commandes de traitement des donn√©es"""
    pass

@process.command()
@click.option('--mode', default='local', type=click.Choice(['local', 'cluster']), 
              help='Mode d\'ex√©cution Spark')
@click.option('--input', help='Chemin du fichier d\'entr√©e pour le mode batch')
@click.option('--output', help='Chemin de sortie pour le mode batch')
@click.option('--streaming', is_flag=True, help='Mode streaming au lieu de batch')
def spark(mode, input, output, streaming):
    """Lance le traitement Spark"""
    logger.info(f"D√©marrage du traitement Spark en mode {mode}")
    
    try:
        from data_processing.spark_jobs.meteo_processor import MeteoSparkProcessor, run_batch_processing, run_streaming_processing
        
        if streaming:
            click.echo("üåä Lancement du traitement Spark Streaming...")
            click.echo("üì° Lecture depuis Kafka...")
            click.echo("‚èπÔ∏è  Ctrl+C pour arr√™ter")
            
            try:
                run_streaming_processing()
            except KeyboardInterrupt:
                click.echo("\n‚èπÔ∏è Traitement streaming arr√™t√©")
        
        else:
            # Mode batch
            if not input:
                # Utiliser le dernier fichier g√©n√©r√©
                import glob
                files = glob.glob(str(config.DATA_DIR / "raw" / "meteo_*.csv"))
                if files:
                    input = max(files, key=lambda x: os.path.getctime(x))  # Dernier fichier
                    click.echo(f"üìÅ Fichier d'entr√©e automatique: {input}")
                else:
                    click.echo("‚ùå Aucun fichier d'entr√©e trouv√©")
                    click.echo("üí° Lancez d'abord: python main.py collect meteo --save")
                    return
            
            if not output:
                output = str(config.DATA_DIR / "processed" / f"meteo_processed_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
            
            click.echo(f"‚ö° Traitement Spark batch:")
            click.echo(f"  üì• Entr√©e: {input}")
            click.echo(f"  üì§ Sortie: {output}")
            
            result = run_batch_processing(input, output)
            
            if result is not None and not result.count() == 0:
                click.echo("‚úÖ Traitement Spark termin√© avec succ√®s")
                click.echo(f"üìä {result.count()} enregistrements trait√©s")
                
                # Afficher quelques statistiques
                click.echo("\nüìà Aper√ßu des m√©triques calcul√©es:")
                result.select("station", "temperature", "temp_moy_7j", "indice_confort").show(5, truncate=False)
            else:
                click.echo("‚ùå √âchec du traitement Spark")
        
    except ImportError as e:
        click.echo(f"‚ùå Erreur d'import Spark: {e}")
        click.echo("üí° V√©rifiez l'installation de PySpark")
    except Exception as e:
        logger.error(f"Erreur Spark: {e}")
        click.echo(f"‚ùå Erreur: {e}")

@process.command()
@click.option('--topics', default='meteo', 
              type=click.Choice(['meteo', 'alertes', 'all']),
              help='Topics Kafka √† traiter')
def kafka(topics):
    """Lance le streaming Kafka"""
    logger.info(f"D√©marrage du streaming Kafka pour {topics}")
    
    try:
        from kafka import KafkaConsumer
        import json
        
        # Configuration des topics selon le choix
        if topics == 'meteo':
            topic_list = [KafkaConfig.TOPIC_METEO_TEMPS_REEL]
        elif topics == 'alertes':
            topic_list = [KafkaConfig.TOPIC_ALERTES_METEO]
        else:
            topic_list = [
                KafkaConfig.TOPIC_METEO_TEMPS_REEL,
                KafkaConfig.TOPIC_ALERTES_METEO,
                KafkaConfig.TOPIC_EVENEMENTS_URBAINS
            ]
        
        click.echo(f"üì° D√©marrage des consommateurs Kafka...")
        click.echo(f"üéØ Topics: {', '.join(topic_list)}")
        click.echo("‚èπÔ∏è  Ctrl+C pour arr√™ter")
        
        # Cr√©er le consommateur
        consumer = KafkaConsumer(
            *topic_list,
            bootstrap_servers=KafkaConfig.BOOTSTRAP_SERVERS,
            value_deserializer=lambda m: json.loads(m.decode('utf-8')),
            group_id=KafkaConfig.GROUP_ID,
            auto_offset_reset='latest'
        )
        
        message_count = 0
        
        try:
            for message in consumer:
                message_count += 1
                
                topic = message.topic
                value = message.value
                timestamp = datetime.fromtimestamp(message.timestamp / 1000)
                
                click.echo(f"\nüì® Message {message_count} re√ßu:")
                click.echo(f"  üéØ Topic: {topic}")
                click.echo(f"  ‚è∞ Timestamp: {timestamp}")
                
                if topic == KafkaConfig.TOPIC_METEO_TEMPS_REEL:
                    station = value.get('station', 'Unknown')
                    temp = value.get('temperature', 'N/A')
                    humidity = value.get('humidite', 'N/A')
                    click.echo(f"  üå°Ô∏è Station: {station}")
                    click.echo(f"  üå°Ô∏è Temp√©rature: {temp}¬∞C")
                    click.echo(f"  üíß Humidit√©: {humidity}%")
                
                elif topic == KafkaConfig.TOPIC_ALERTES_METEO:
                    alert_type = value.get('type_alerte', 'Unknown')
                    level = value.get('niveau', 'Unknown')
                    click.echo(f"  üö® Type: {alert_type}")
                    click.echo(f"  ‚ö†Ô∏è Niveau: {level}")
                
                else:
                    click.echo(f"  üìÑ Donn√©es: {str(value)[:100]}...")
                
                # Pause pour la lisibilit√©
                time.sleep(0.5)
                
        except KeyboardInterrupt:
            click.echo(f"\n‚èπÔ∏è Arr√™t du streaming Kafka ({message_count} messages trait√©s)")
        finally:
            consumer.close()
        
    except ImportError as e:
        click.echo(f"‚ùå Erreur d'import Kafka: {e}")
        click.echo("üí° Installez kafka-python")
    except Exception as e:
        logger.error(f"Erreur Kafka: {e}")
        click.echo(f"‚ùå Erreur: {e}")

@process.command()
@click.option('--pipeline', default='full', 
              type=click.Choice(['collect', 'kafka', 'spark', 'full']),
              help='Pipeline √† ex√©cuter')
def pipeline(pipeline):
    """Lance le pipeline complet de traitement"""
    logger.info(f"Lancement du pipeline: {pipeline}")
    
    try:
        if pipeline in ['collect', 'full']:
            click.echo("üîÑ √âtape 1: Collecte des donn√©es...")
            
            # Collecte et envoi vers Kafka
            from data_collection.collectors.toulouse_collector import CombinedMeteoCollector
            collector = CombinedMeteoCollector()
            data = collector.collect_all_stations(limit=10, send_to_kafka=True)
            
            if not data.empty:
                click.echo(f"‚úÖ {len(data)} enregistrements collect√©s et envoy√©s vers Kafka")
                
                # Sauvegarde pour Spark batch
                filename = config.DATA_DIR / "raw" / f"pipeline_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                data.to_csv(filename, index=False)
                click.echo(f"üíæ Donn√©es sauvegard√©es: {filename}")
            else:
                click.echo("‚ùå √âchec de la collecte")
                return
        
        if pipeline in ['spark', 'full']:
            click.echo("\n‚ö° √âtape 2: Traitement Spark...")
            
            # Lancer traitement Spark en mode batch
            import glob
            files = glob.glob(str(config.DATA_DIR / "raw" / "*.csv"))
            if files:
                latest_file = max(files, key=lambda x: os.path.getctime(x))
                output_dir = config.DATA_DIR / "processed" / f"spark_output_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                
                from data_processing.spark_jobs.meteo_processor import run_batch_processing
                result = run_batch_processing(latest_file, str(output_dir))
                
                if result is not None:
                    click.echo(f"‚úÖ Traitement Spark termin√©: {result.count()} enregistrements")
                else:
                    click.echo("‚ùå √âchec traitement Spark")
            else:
                click.echo("‚ùå Aucun fichier de donn√©es trouv√©")
        
        if pipeline == 'full':
            click.echo("\nüåê √âtape 3: Interface disponible")
            click.echo("üí° Lancez: python main.py web streamlit")
        
        click.echo(f"\nüéâ Pipeline {pipeline} termin√© avec succ√®s!")
        
    except Exception as e:
        logger.error(f"Erreur pipeline: {e}")
        click.echo(f"‚ùå Erreur pipeline: {e}")

# Ajouter l'import n√©cessaire en haut du fichier
import os
import time
from datetime import datetime

@cli.group()
def web():
    """Commandes interface web"""
    pass

@web.command()
@click.option('--port', default=8501, help='Port Streamlit')
@click.option('--host', default='localhost', help='Host Streamlit')
def streamlit(port, host):
    """Lance l'interface Streamlit"""
    logger.info(f"D√©marrage Streamlit sur {host}:{port}")
    
    import subprocess
    import sys
    
    try:
        streamlit_path = config.BASE_DIR / "web-interface" / "streamlit-app" / "main.py"
        
        if not streamlit_path.exists():
            click.echo(f"‚ùå Fichier Streamlit non trouv√©: {streamlit_path}")
            click.echo("Cr√©ez le fichier avec: python main.py setup streamlit")
            return
        
        cmd = [
            sys.executable, "-m", "streamlit", "run", 
            str(streamlit_path),
            "--server.port", str(port),
            "--server.address", host
        ]
        
        click.echo(f"üåê Lancement Streamlit sur http://{host}:{port}")
        subprocess.run(cmd)
        
    except KeyboardInterrupt:
        click.echo("\n‚èπÔ∏è Arr√™t de Streamlit")
    except Exception as e:
        logger.error(f"Erreur Streamlit: {e}")
        click.echo(f"‚ùå Erreur: {e}")

@web.command()
def api():
    """Lance l'API FastAPI"""
    logger.info("D√©marrage API FastAPI")
    
    try:
        from web_interface.api.main import app
        import uvicorn
        from config import WebConfig
        
        click.echo(f"üöÄ Lancement API sur http://{WebConfig.FASTAPI_HOST}:{WebConfig.FASTAPI_PORT}")
        uvicorn.run(app, host=WebConfig.FASTAPI_HOST, port=WebConfig.FASTAPI_PORT)
        
    except Exception as e:
        logger.error(f"Erreur API: {e}")
        click.echo(f"‚ùå Erreur: {e}")

@cli.group()
def docker():
    """Commandes Docker"""
    pass

@docker.command()
def up():
    """Lance tous les services Docker"""
    logger.info("Lancement des services Docker")
    
    import subprocess
    
    try:
        click.echo("üê≥ Lancement de Docker Compose...")
        result = subprocess.run(["docker-compose", "up", "-d"], 
                              capture_output=True, text=True)
        
        if result.returncode == 0:
            click.echo("‚úÖ Services Docker lanc√©s")
            click.echo("\nüìã Services disponibles:")
            click.echo("  ‚Ä¢ Streamlit:     http://localhost:8501")
            click.echo("  ‚Ä¢ Kafka UI:      http://localhost:8085") 
            click.echo("  ‚Ä¢ NiFi:          http://localhost:8080")
            click.echo("  ‚Ä¢ Spark Master:  http://localhost:9090")
            click.echo("  ‚Ä¢ PgAdmin:       http://localhost:5050")
            click.echo("  ‚Ä¢ Mongo Express: http://localhost:8081")
        else:
            click.echo(f"‚ùå Erreur Docker: {result.stderr}")
            
    except FileNotFoundError:
        click.echo("‚ùå Docker Compose non trouv√©. Installez Docker.")
    except Exception as e:
        click.echo(f"‚ùå Erreur: {e}")

@docker.command()
def down():
    """Arr√™te tous les services Docker"""
    logger.info("Arr√™t des services Docker")
    
    import subprocess
    
    try:
        click.echo("üê≥ Arr√™t de Docker Compose...")
        result = subprocess.run(["docker-compose", "down"], 
                              capture_output=True, text=True)
        
        if result.returncode == 0:
            click.echo("‚úÖ Services Docker arr√™t√©s")
        else:
            click.echo(f"‚ùå Erreur Docker: {result.stderr}")
            
    except Exception as e:
        click.echo(f"‚ùå Erreur: {e}")

@docker.command()
def status():
    """Affiche le statut des services Docker"""
    import subprocess
    
    try:
        click.echo("üîç Statut des services Docker:")
        subprocess.run(["docker-compose", "ps"])
    except Exception as e:
        click.echo(f"‚ùå Erreur: {e}")

@cli.group()
def setup():
    """Commandes de configuration initiale"""
    pass

@setup.command()
def install():
    """Installation compl√®te du projet"""
    click.echo("üöÄ Installation de la plateforme m√©t√©o Toulouse")
    
    # V√©rification Python
    python_version = sys.version_info
    if python_version < (3, 8):
        click.echo("‚ùå Python 3.8+ requis")
        return
    
    click.echo(f"‚úÖ Python {python_version.major}.{python_version.minor}")
    
    # Installation des d√©pendances
    import subprocess
    
    try:
        click.echo("üì¶ Installation des d√©pendances...")
        subprocess.run([sys.executable, "-m", "pip", "install", "-r", "requirements.txt"], 
                      check=True)
        click.echo("‚úÖ D√©pendances install√©es")
    except subprocess.CalledProcessError:
        click.echo("‚ùå Erreur lors de l'installation des d√©pendances")
        return
    
    # Cr√©ation des dossiers
    click.echo("üìÅ Cr√©ation de la structure...")
    for folder in ["data/raw", "data/processed", "data/exports", "logs"]:
        (config.BASE_DIR / folder).mkdir(parents=True, exist_ok=True)
    
    # Cr√©ation du .env
    env_file = config.BASE_DIR / ".env"
    if not env_file.exists():
        click.echo("‚öôÔ∏è Cr√©ation du fichier .env...")
        env_example = config.BASE_DIR / ".env.example"
        if env_example.exists():
            import shutil
            shutil.copy(env_example, env_file)
            click.echo("‚úÖ Fichier .env cr√©√© (√©ditez-le pour vos param√®tres)")
    
    click.echo("\nüéâ Installation termin√©e !")
    click.echo("\nüìã Prochaines √©tapes:")
    click.echo("  1. √âditez le fichier .env avec vos configurations")
    click.echo("  2. Lancez: python main.py docker up")
    click.echo("  3. Initialisez les DB: python main.py db init")
    click.echo("  4. Testez la collecte: python main.py collect meteo")
    click.echo("  5. Lancez l'interface: python main.py web streamlit")

@setup.command()
def streamlit():
    """Cr√©e l'application Streamlit de base"""
    click.echo("üåê Cr√©ation de l'application Streamlit")
    
    streamlit_dir = config.BASE_DIR / "web-interface" / "streamlit-app"
    streamlit_dir.mkdir(parents=True, exist_ok=True)
    
    # Cr√©ation du fichier Streamlit principal
    streamlit_main = streamlit_dir / "main.py"
    
    streamlit_content = '''import streamlit as st
import sys
from pathlib import Path

# Ajouter le r√©pertoire racine au PYTHONPATH
sys.path.append(str(Path(__file__).parent.parent.parent.absolute()))

from web_interface.streamlit_app.meteo_search_engine import main

if __name__ == "__main__":
    main()
'''
    
    with open(streamlit_main, 'w', encoding='utf-8') as f:
        f.write(streamlit_content)
    
    click.echo(f"‚úÖ Fichier Streamlit cr√©√©: {streamlit_main}")

@setup.command()
def examples():
    """G√©n√®re des donn√©es d'exemple"""
    click.echo("üìä G√©n√©ration de donn√©es d'exemple")
    
    try:
        from data_collection.collectors.toulouse_collector import ToulouseMeteoCollector
        import pandas as pd
        import numpy as np
        from datetime import datetime, timedelta
        
        # Donn√©es simul√©es
        click.echo("üé≤ G√©n√©ration de donn√©es m√©t√©o simul√©es...")
        
        dates = pd.date_range(
            start=datetime.now() - timedelta(days=30), 
            end=datetime.now(), 
            freq='H'
        )
        
        np.random.seed(42)
        data = pd.DataFrame({
            'timestamp': dates,
            'temperature': 15 + 10 * np.sin(np.arange(len(dates)) * 2 * np.pi / (24 * 365)) + np.random.normal(0, 3, len(dates)),
            'humidite': 50 + 30 * np.random.random(len(dates)),
            'pression': 1013 + np.random.normal(0, 10, len(dates)),
            'vitesse_vent': np.random.normal(8, len(dates)),
            'direction_vent': np.random.uniform(0, 360, len(dates)),
            'precipitation': np.where(np.random.random(len(dates)) < 0.2, np.random.normal(2), 0)
        })
        
        # Sauvegarde
        example_file = config.DATA_DIR / "raw" / "example_meteo_data.csv"
        data.to_csv(example_file, index=False)
        
        click.echo(f"‚úÖ {len(data)} enregistrements d'exemple cr√©√©s dans {example_file}")
        
    except Exception as e:
        click.echo(f"‚ùå Erreur: {e}")

@cli.command()
def test():
    """Lance les tests unitaires"""
    logger.info("Lancement des tests")
    
    import subprocess
    
    try:
        click.echo("üß™ Lancement des tests...")
        result = subprocess.run(["python", "-m", "pytest", "tests/", "-v"], 
                              capture_output=True, text=True)
        
        click.echo(result.stdout)
        if result.stderr:
            click.echo(result.stderr)
            
        if result.returncode == 0:
            click.echo("‚úÖ Tous les tests passent")
        else:
            click.echo("‚ùå Certains tests √©chouent")
            
    except FileNotFoundError:
        click.echo("‚ùå pytest non trouv√©. Installez avec: pip install pytest")
    except Exception as e:
        click.echo(f"‚ùå Erreur: {e}")

@cli.command()
def info():
    """Affiche les informations sur la plateforme"""
    click.echo(f"""
üå§Ô∏è {config.APP_NAME} v{config.APP_VERSION}

üìä Configuration:
  ‚Ä¢ Mode Debug: {config.DEBUG}
  ‚Ä¢ R√©pertoire: {config.BASE_DIR}
  ‚Ä¢ Logs: {config.LOG_LEVEL}

üóÑÔ∏è Bases de donn√©es:
  ‚Ä¢ PostgreSQL: {DatabaseConfig.POSTGRES_HOST}:{DatabaseConfig.POSTGRES_PORT}
  ‚Ä¢ MongoDB: {DatabaseConfig.MONGODB_HOST}:{DatabaseConfig.MONGODB_PORT}
  ‚Ä¢ SQLite: {DatabaseConfig.SQLITE_PATH}

üì° Services:
  ‚Ä¢ Kafka: {', '.join(KafkaConfig.BOOTSTRAP_SERVERS)}
  ‚Ä¢ Spark: {SparkConfig.MASTER_URL}

üåê Web:
  ‚Ä¢ Streamlit: http://localhost:{WebConfig.STREAMLIT_PORT}
  ‚Ä¢ API: http://localhost:{WebConfig.FASTAPI_PORT}

üìã Commandes disponibles:
  ‚Ä¢ python main.py collect meteo    - Collecte donn√©es m√©t√©o
  ‚Ä¢ python main.py docker up       - Lance tous les services
  ‚Ä¢ python main.py web streamlit   - Interface utilisateur
  ‚Ä¢ python main.py db status       - Statut des bases
  ‚Ä¢ python main.py setup install   - Installation compl√®te
""")

if __name__ == "__main__":
    try:
        cli()
    except KeyboardInterrupt:
        click.echo("\nüëã Au revoir !")
    except Exception as e:
        logger.error(f"Erreur inattendue: {e}")
        click.echo(f"‚ùå Erreur inattendue: {e}")
        sys.exit(1)