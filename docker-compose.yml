services:
  # =============================================================================
  # KAFKA & ZOOKEEPER
  # =============================================================================
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-logs:/var/lib/zookeeper/log

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    hostname: kafka
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "9997:9997"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9997
      KAFKA_JMX_HOSTNAME: localhost
    volumes:
      - kafka-data:/var/lib/kafka/data

  # =============================================================================
  # DATABASES
  # =============================================================================
  postgres:
    image: postgres:15
    container_name: postgres_meteo
    restart: always
    environment:
      POSTGRES_DB: meteo_toulouse
      POSTGRES_USER: meteo_user
      POSTGRES_PASSWORD: meteo_pass
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./sql/init.sql:/docker-entrypoint-initdb.d/init.sql

  mongodb:
    image: mongo:7.0
    container_name: mongodb_meteo
    restart: always
    environment:
      MONGO_INITDB_ROOT_USERNAME: meteo_user
      MONGO_INITDB_ROOT_PASSWORD: meteo_pass
      MONGO_INITDB_DATABASE: meteo_events
    ports:
      - "27017:27017"
    volumes:
      - mongodb-data:/data/db

  # =============================================================================
  # APACHE NIFI
  # =============================================================================
  nifi:
    image: apache/nifi:1.23.2
    container_name: nifi_meteo
    restart: always
    ports:
      - "8443:8443"
      - "8080:8080"
    environment:
      - SINGLE_USER_CREDENTIALS_USERNAME=admin
      - SINGLE_USER_CREDENTIALS_PASSWORD=adminpassword
      - NIFI_WEB_HTTPS_PORT=8443
      - NIFI_WEB_HTTP_PORT=8080
    volumes:
      - nifi-logs:/opt/nifi/nifi-current/logs
      - nifi-conf:/opt/nifi/nifi-current/conf
      - ./nifi-processors:/opt/nifi/nifi-current/processors

  # =============================================================================
  # SPARK
  # =============================================================================
  spark-master:
    image: bitnami/spark:3.5
    container_name: spark-master
    command: bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "9090:8080"
      - "7077:7077"
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./jars:/opt/bitnami/spark/jars

  spark-worker:
    image: bitnami/spark:3.5
    container_name: spark-worker
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./spark-apps:/opt/spark-apps

  # =============================================================================
  # APPLICATION SERVICES
  # =============================================================================
  meteo-collector:
    build:
      context: .
      dockerfile: Dockerfile.collector
    container_name: meteo-collector
    restart: always
    depends_on:
      - kafka
      - postgres
      - mongodb
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - POSTGRES_URL=postgresql://meteo_user:meteo_pass@postgres:5432/meteo_toulouse
      - MONGODB_URL=mongodb://meteo_user:meteo_pass@mongodb:27017/meteo_events
    volumes:
      - ./data:/app/data
    command: python collector_service.py

  meteo-processor:
    build:
      context: .
      dockerfile: Dockerfile.processor
    container_name: meteo-processor
    restart: always
    depends_on:
      - kafka
      - spark-master
      - postgres
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - SPARK_MASTER_URL=spark://spark-master:7077
      - POSTGRES_URL=postgresql://meteo_user:meteo_pass@postgres:5432/meteo_toulouse
    volumes:
      - ./spark-apps:/app/spark-apps
    command: python processor_service.py

  # =============================================================================
  # WEB INTERFACE
  # =============================================================================
  streamlit-app:
    build:
      context: .
      dockerfile: Dockerfile.streamlit
    container_name: streamlit-meteo
    restart: always
    ports:
      - "8501:8501"
    depends_on:
      - postgres
      - mongodb
    environment:
      - POSTGRES_URL=postgresql://meteo_user:meteo_pass@postgres:5432/meteo_toulouse
      - MONGODB_URL=mongodb://meteo_user:meteo_pass@mongodb:27017/meteo_events
    volumes:
      - ./streamlit-app:/app
    command: streamlit run main.py --server.address 0.0.0.0

  # =============================================================================
  # MONITORING & UTILITIES
  # =============================================================================
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      - kafka
    ports:
      - "8085:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092

  pgadmin:
    image: dpage/pgadmin4
    container_name: pgadmin
    restart: always
    ports:
      - "5050:80"
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@meteo.local
      PGADMIN_DEFAULT_PASSWORD: admin
    volumes:
      - pgadmin-data:/var/lib/pgadmin

  mongo-express:
    image: mongo-express
    container_name: mongo-express
    restart: always
    ports:
      - "8081:8081"
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: meteo_user
      ME_CONFIG_MONGODB_ADMINPASSWORD: meteo_pass
      ME_CONFIG_MONGODB_URL: mongodb://meteo_user:meteo_pass@mongodb:27017/
    depends_on:
      - mongodb

# =============================================================================
# VOLUMES
# =============================================================================
volumes:
  zookeeper-data:
  zookeeper-logs:
  kafka-data:
  postgres-data:
  mongodb-data:
  nifi-logs:
  nifi-conf:
  pgadmin-data:

# =============================================================================
# NETWORKS
# =============================================================================
networks:
  default:
    name: meteo-network
    driver: bridge